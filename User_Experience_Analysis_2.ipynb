{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "User_Experience_Analysis_2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zUeacBld_PKw"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujatasahoo/User-Experience-Analysis/blob/main/User_Experience_Analysis_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User Experience Analysis Pt. 2\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2BhQV82XSC1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contributors\n",
        "\n",
        "Kristina C.\n",
        "\n",
        "Erin Costolo\n",
        "\n",
        "Sujata Sahoo\n",
        "\n",
        "Roger Vieira\n",
        "\n",
        "<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "tzDdaiObOfgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective\n",
        "\n",
        "The objective of this notebook is to help admins and stakeholders track trends about what brings people to Underdog Devs. We will analyze text responses from applicants and mentees. A previous analysis looked at only single word tokens and did not incorporate the context of other words in the response. We will be performing Natural Language Processing (NLP) by looking at individual words, phrases, and non-consecutive words based on their frequencies in a response. We will also explore topic modeling by performing Latent Dirichlet Allocation (LDA).\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "gQQJR5vwOfdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n"
      ],
      "metadata": {
        "id": "7_HJOpBHOfXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Only run this cell once, then restart runtime\n",
        "!wget https://gist.githubusercontent.com/rogerfvieira/8c5187cc7d080119202d4a069d28f50c/raw/22627ca804d64360a97db9839adccacf53cdb1ef/requirements.txt\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "rlmdmsWtNDWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base\n",
        "from collections import Counter, OrderedDict\n",
        "import json\n",
        "import requests\n",
        "import re\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import altair as alt\n",
        "import pandas as pd\n",
        "\n",
        "# NLP Libraries\n",
        "import spacy\n",
        "\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models"
      ],
      "metadata": {
        "id": "lmCZRKimShQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a2fa41a-633f-437e-beaf-412a9495a089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data from API"
      ],
      "metadata": {
        "id": "wySf7ogeF9YX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mongo_cursor = requests.post('http://underdog-devs-ds-a-dev.us-east-1.elasticbeanstalk.com/Responses/read').json()\n",
        "responses = [obj[\"text\"] for obj in mongo_cursor['result']]"
      ],
      "metadata": {
        "id": "SuBrYDDLQs3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization\\Tokenization"
      ],
      "metadata": {
        "id": "rdStVMH8L7JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize(document):\n",
        "    \"\"\"\n",
        "    Takes document (individual response) and returns list of tokens in the form\n",
        "    of lemmas.\n",
        "    Converts all text to lowercase tokens, removes stop words, punctuation, \n",
        "    numbers, and tokens of blank space\"\n",
        "    \"\"\"\n",
        "    \n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(document)\n",
        "   \n",
        "    lemma_list = [\n",
        "        token.lemma_.lower() for token in doc\n",
        "        if not token.is_stop\n",
        "        and not token.is_punct\n",
        "        and not token.like_num\n",
        "        and not token.is_space\n",
        "    ]\n",
        "    return lemma_list"
      ],
      "metadata": {
        "id": "5tO-28wWEoFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas = [lemmatize(sentences) for sentences in responses]"
      ],
      "metadata": {
        "id": "bUcwzCeomDPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3yJ2g3lWBSG",
        "outputId": "f6e71a31-841a-4d5a-b865-9d767405a972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['mentorship', 'tuning', 'skill', 'point', 'employable'],\n",
              " ['competent', 'coder', 'start', 'successful', 'career'],\n",
              " ['well', 'developer', 'help', 'return'],\n",
              " ['network', 'well', 'opportunity'],\n",
              " ['mentorship', 'help', 'support', 'journey']]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frequency Analysis"
      ],
      "metadata": {
        "id": "s96kvb79Owqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two Word Phrases"
      ],
      "metadata": {
        "id": "CnqR7e5WL37t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "double_tokens = []\n",
        "for response in range(len(lemmas)):\n",
        "    for token in range(len(lemmas[response]) - 1):\n",
        "        double_tokens.append(lemmas[response][token] + ' ' +\n",
        "                             lemmas[response][token+1])"
      ],
      "metadata": {
        "id": "6b2YLArUEgRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq_double = dict(Counter(double_tokens))"
      ],
      "metadata": {
        "id": "UnScZs_QGIww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sort_freq_double = sorted(freq_double.items(), key=lambda x:x[1])"
      ],
      "metadata": {
        "id": "Ia4kh4sfHQfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_double = pd.DataFrame(sort_freq_double, columns=('phrase','frequency'))\n",
        "double_top_20 = df_double[-20:]\n",
        "double_top_20.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PNoV4uJpdjdk",
        "outputId": "2e556219-d3fd-4a2c-c40d-6c8c21b95107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 phrase  frequency\n",
              "2258  software engineer          7\n",
              "2259           land job          8\n",
              "2260       ask question          8\n",
              "2261     gain knowledge          8\n",
              "2262          hope gain         18"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d8ac9a5-36f5-44f6-be7e-2d2c8ea3d2c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2258</th>\n",
              "      <td>software engineer</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2259</th>\n",
              "      <td>land job</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2260</th>\n",
              "      <td>ask question</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261</th>\n",
              "      <td>gain knowledge</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262</th>\n",
              "      <td>hope gain</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d8ac9a5-36f5-44f6-be7e-2d2c8ea3d2c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d8ac9a5-36f5-44f6-be7e-2d2c8ea3d2c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d8ac9a5-36f5-44f6-be7e-2d2c8ea3d2c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "double_graph = alt.Chart(\n",
        "                    double_top_20,\n",
        "                    title=\"Top 20 Most Common Phrases in User Responses\"\n",
        "                    ).mark_bar().encode(\n",
        "                        x=alt.X(\"frequency:Q\",\n",
        "                                title='Frequency'),\n",
        "                        y=alt.Y(\"phrase:O\",\n",
        "                                title='Phrases',\n",
        "                                sort=\"-x\",\n",
        "                                scale=alt.Scale()\n",
        "                                ))\n",
        "double_graph.display()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "Zr8l_koyebTU",
        "outputId": "49c07e6b-18bb-4515-fe02-1cd1da22508d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<div id=\"altair-viz-b64907e906a247d99be696841455201e\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-b64907e906a247d99be696841455201e\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-b64907e906a247d99be696841455201e\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-17b2df9a983eb460d3778d144866250e\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"field\": \"frequency\", \"title\": \"Frequency\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"phrase\", \"scale\": {}, \"sort\": \"-x\", \"title\": \"Phrases\", \"type\": \"ordinal\"}}, \"title\": \"Top 20 Most Common Phrases in User Responses\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-17b2df9a983eb460d3778d144866250e\": [{\"phrase\": \"like learn\", \"frequency\": 4}, {\"phrase\": \"software developer\", \"frequency\": 4}, {\"phrase\": \"want help\", \"frequency\": 4}, {\"phrase\": \"job software\", \"frequency\": 4}, {\"phrase\": \"job tech\", \"frequency\": 5}, {\"phrase\": \"job opportunity\", \"frequency\": 5}, {\"phrase\": \"learn code\", \"frequency\": 5}, {\"phrase\": \"ios developer\", \"frequency\": 5}, {\"phrase\": \"software engineering\", \"frequency\": 5}, {\"phrase\": \"help people\", \"frequency\": 5}, {\"phrase\": \"gain skill\", \"frequency\": 5}, {\"phrase\": \"pay forward\", \"frequency\": 5}, {\"phrase\": \"software development\", \"frequency\": 6}, {\"phrase\": \"well understanding\", \"frequency\": 6}, {\"phrase\": \"feel like\", \"frequency\": 6}, {\"phrase\": \"software engineer\", \"frequency\": 7}, {\"phrase\": \"land job\", \"frequency\": 8}, {\"phrase\": \"ask question\", \"frequency\": 8}, {\"phrase\": \"gain knowledge\", \"frequency\": 8}, {\"phrase\": \"hope gain\", \"frequency\": 18}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Three Word Phrases"
      ],
      "metadata": {
        "id": "_TfhHIx7bL0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "triple_tokens = []\n",
        "for response in range(len(lemmas)):\n",
        "    for j in range(len(lemmas[response]) - 2):\n",
        "        triple_tokens.append(lemmas[response][j] + ' ' +\n",
        "                                 lemmas[response][j+1] + ' ' +\n",
        "                                 lemmas[response][j+2])"
      ],
      "metadata": {
        "id": "Ok0n_ATvJBw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq_triple = dict(Counter(triple_tokens))"
      ],
      "metadata": {
        "id": "wcDdI-sXJL9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sort_freq_triple = sorted(freq_triple.items(), key=lambda x:x[1])"
      ],
      "metadata": {
        "id": "fHUOR7VVJZ86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_triple = pd.DataFrame(sort_freq_triple, columns=('phrase','frequency'))\n",
        "triple_top_20 = df_triple[-20:]\n",
        "triple_top_20.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FEwy0-pSfYQ2",
        "outputId": "596eadd2-26f9-4e5e-e00b-aa82bb013af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        phrase  frequency\n",
              "2240  well understanding stack          2\n",
              "2241        new direction life          3\n",
              "2242  direction life financial          3\n",
              "2243  life financial stability          3\n",
              "2244       hope gain knowledge          3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d2b468e-9c65-4cd4-a2eb-2603f67c7229\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2240</th>\n",
              "      <td>well understanding stack</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2241</th>\n",
              "      <td>new direction life</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2242</th>\n",
              "      <td>direction life financial</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2243</th>\n",
              "      <td>life financial stability</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2244</th>\n",
              "      <td>hope gain knowledge</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d2b468e-9c65-4cd4-a2eb-2603f67c7229')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d2b468e-9c65-4cd4-a2eb-2603f67c7229 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d2b468e-9c65-4cd4-a2eb-2603f67c7229');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "triple_graph = alt.Chart(\n",
        "                    triple_top_20,\n",
        "                    title=\"Top 20 Most Common Phrases in User Responses\"\n",
        "                    ).mark_bar().encode(\n",
        "                        x=alt.X(\"frequency:Q\",\n",
        "                                title='Frequency',\n",
        "                                axis=alt.Axis(tickMinStep=1)\n",
        "                                ),\n",
        "                        y=alt.Y(\"phrase:O\",\n",
        "                                title='Phrases',\n",
        "                                sort=\"-x\")\n",
        "                                )\n",
        "triple_graph.display()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "ou5w2FnOfFeb",
        "outputId": "cd0c300c-e41e-4d7c-e181-ac15dd01f63f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<div id=\"altair-viz-72bf8b5d5806423eae780562c8dedc9b\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-72bf8b5d5806423eae780562c8dedc9b\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-72bf8b5d5806423eae780562c8dedc9b\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-36555d1d6bc5d173559713231a2cad51\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"axis\": {\"tickMinStep\": 1}, \"field\": \"frequency\", \"title\": \"Frequency\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"phrase\", \"sort\": \"-x\", \"title\": \"Phrases\", \"type\": \"ordinal\"}}, \"title\": \"Top 20 Most Common Phrases in User Responses\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-36555d1d6bc5d173559713231a2cad51\": [{\"phrase\": \"people similar situation\", \"frequency\": 2}, {\"phrase\": \"help learn code\", \"frequency\": 2}, {\"phrase\": \"hope gain mentor\", \"frequency\": 2}, {\"phrase\": \"gain well understanding\", \"frequency\": 2}, {\"phrase\": \"help foot door\", \"frequency\": 2}, {\"phrase\": \"learn new skill\", \"frequency\": 2}, {\"phrase\": \"career software developer\", \"frequency\": 2}, {\"phrase\": \"self teach developer\", \"frequency\": 2}, {\"phrase\": \"far code journey\", \"frequency\": 2}, {\"phrase\": \"skill land job\", \"frequency\": 2}, {\"phrase\": \"gain skill need\", \"frequency\": 2}, {\"phrase\": \"computer skill network\", \"frequency\": 2}, {\"phrase\": \"skill network build\", \"frequency\": 2}, {\"phrase\": \"network build confidence\", \"frequency\": 2}, {\"phrase\": \"job software development\", \"frequency\": 2}, {\"phrase\": \"well understanding stack\", \"frequency\": 2}, {\"phrase\": \"new direction life\", \"frequency\": 3}, {\"phrase\": \"direction life financial\", \"frequency\": 3}, {\"phrase\": \"life financial stability\", \"frequency\": 3}, {\"phrase\": \"hope gain knowledge\", \"frequency\": 3}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More Data Exploration"
      ],
      "metadata": {
        "id": "4oOoJt-GB6GD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ-YelEKNzOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd9eeca-aa3c-4b42-e331-f6662d2b0aed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'career software developer': 2,\n",
              " 'computer skill network': 2,\n",
              " 'direction life financial': 3,\n",
              " 'far code journey': 2,\n",
              " 'gain skill need': 2,\n",
              " 'gain well understanding': 2,\n",
              " 'help foot door': 2,\n",
              " 'help learn code': 2,\n",
              " 'high pay job': 2,\n",
              " 'hope gain knowledge': 3,\n",
              " 'hope gain mentor': 2,\n",
              " 'job software development': 2,\n",
              " 'learn new skill': 2,\n",
              " 'life financial stability': 3,\n",
              " 'like minded individual': 2,\n",
              " 'network build confidence': 2,\n",
              " 'new direction life': 3,\n",
              " 'people similar situation': 2,\n",
              " 'self teach developer': 2,\n",
              " 'skill land job': 2,\n",
              " 'skill network build': 2,\n",
              " 'well understanding stack': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# view all 3 word phrases that appear more than once across all docs\n",
        "freq3_2 = {key:value for (key,value) in freq_triple.items() if value > 1}\n",
        "freq3_2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two Nonconsecutive Tokens From Responses\n",
        "Frequency analysis on any two words in one response, not only consequetive ones.\n"
      ],
      "metadata": {
        "id": "wS57qlHJCCR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "two_tokens = []\n",
        "for i in range(len(lemmas)):\n",
        "    for j in range(len(lemmas[i]) - 1):\n",
        "        for k in range(j + 1, len(lemmas[i])):\n",
        "            new = sorted([lemmas[i][j], lemmas[i][k]])\n",
        "            two_tokens.append(new[0] + ' ' + new[1])"
      ],
      "metadata": {
        "id": "nuqY7XSrOwdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq_two = dict(Counter(two_tokens))"
      ],
      "metadata": {
        "id": "4z9C7tQDQJtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sort_freq_two = sorted(freq_two.items(), key=lambda x:x[1])\n",
        "sort_freq_two[-20:]"
      ],
      "metadata": {
        "id": "0ChM2XR4QSV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4edd145d-b684-4a47-cd82-47b7bb38540a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('community learn', 15),\n",
              " ('like mentor', 15),\n",
              " ('hope job', 16),\n",
              " ('community people', 16),\n",
              " ('hope skill', 17),\n",
              " ('job mentor', 17),\n",
              " ('learn skill', 17),\n",
              " ('good learn', 17),\n",
              " ('learn people', 18),\n",
              " ('help skill', 19),\n",
              " ('help want', 20),\n",
              " ('learn like', 21),\n",
              " ('like people', 21),\n",
              " ('help people', 21),\n",
              " ('job learn', 22),\n",
              " ('help job', 24),\n",
              " ('help learn', 26),\n",
              " ('job skill', 27),\n",
              " ('gain hope', 27),\n",
              " ('help like', 33)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Three Nonconsecutive Tokens"
      ],
      "metadata": {
        "id": "nW1Bhg2fDDo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "three_tokens = []\n",
        "for i in range(len(lemmas)):\n",
        "    for j in range(len(lemmas[i]) - 2):\n",
        "        for k in range(j + 1, len(lemmas[i]) - 1):\n",
        "            for l in range(k + 1, len(lemmas[i])):\n",
        "                new = sorted([lemmas[i][j], lemmas[i][k], lemmas[i][l]])\n",
        "                three_tokens.append(new[0] + ' ' +  new[1] + ' ' + new[2])"
      ],
      "metadata": {
        "id": "Rr_VBBncQ_PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq_three = dict(Counter(three_tokens))"
      ],
      "metadata": {
        "id": "YV4UQUt2RzWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sort_freq_three = sorted(freq_three.items(), key=lambda x:x[1])\n",
        "sort_freq_three[-20:]"
      ],
      "metadata": {
        "id": "p3bQmK2dR57R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "791bd138-439b-4707-978b-cda096e94151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('help race want', 18),\n",
              " ('experience help people', 19),\n",
              " ('experience job people', 19),\n",
              " ('good help learn', 19),\n",
              " ('people situation understand', 19),\n",
              " ('like people situation', 19),\n",
              " ('like people understand', 19),\n",
              " ('like understanding well', 20),\n",
              " ('help understanding well', 20),\n",
              " ('help learn like', 22),\n",
              " ('hard learn people', 24),\n",
              " ('good learn people', 24),\n",
              " ('learn people understand', 24),\n",
              " ('experience learn people', 25),\n",
              " ('learn people situation', 25),\n",
              " ('help learn people', 25),\n",
              " ('learn like people', 25),\n",
              " ('job learn people', 25),\n",
              " ('help like people', 27),\n",
              " ('bear race want', 27)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic modeling and LDA:\n",
        "Topic modeling allows the user to explore the content of the documents and build new connections between topics they might not have been aware of. Latent Dirichlet Allocation (LDA) is a type of topic modeling in which words are represented as topics, and documents are represented as a collection of these word topics.\n",
        " \tA useful topic model has big non-overlapping circles scattered throughout the chart instead of being clustered in one quadrant. The package also allows the user to observe the most relevant keywords from the selected topic."
      ],
      "metadata": {
        "id": "s_zXUvO97S8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Latent Dirichlet Allocation(LDA) Model with gensim\n",
        "\n",
        "\n",
        "**The two main inputs to the genesim LDA topic model are the dictionary(id2word) and the corpus.**\n",
        "\n",
        "\n",
        "\n",
        "*   The id2word is a special object that keeps track of the mapping from text to numerical index, and the mapping from numerical index back to text.\n",
        "*   The corpus is a specially formatted list containing information about each document.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zUeacBld_PKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create the id2word dictionary**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8URqx_rbHDlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2word = corpora.Dictionary(lemmas)"
      ],
      "metadata": {
        "id": "at9yUdjjQ04j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "b6e23742-5241-4fb1-bb63-51edffeb7436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d6daaa5d855c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'corpora' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [id2word.doc2bow(doc_lemmas) for doc_lemmas in lemmas]"
      ],
      "metadata": {
        "id": "HMk9yKGyRmwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_words = [len(lemmas[i]) for i in range(len(lemmas))]\n",
        "sorted(n_of_words)[-10:]"
      ],
      "metadata": {
        "id": "neWWApV0v0eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train an LDA model"
      ],
      "metadata": {
        "id": "HNIt8zj_ITqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_topics = 3\n",
        "\n",
        "lda_multicore_3_topics = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
        "                                                        id2word=id2word,\n",
        "                                                        num_topics=num_topics, \n",
        "                                                        chunksize=100,\n",
        "                                                        passes=10,\n",
        "                                                        per_word_topics=True,\n",
        "                                                        workers=1, \n",
        "                                                        random_state=1234, \n",
        "                                                        iterations=10) "
      ],
      "metadata": {
        "id": "GqaU_5sETNRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretion of LDA results and Selection of the appropriate number of topics\n",
        "\n",
        "\n",
        "*   LDAvis provides an interactive visualization of the topics estimated using Latent Dirichlet Allocation(LDA)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tgIEJf8WsQE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualising the topics in the model"
      ],
      "metadata": {
        "id": "CqOMFo9NtJP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_multicore_3_topics, corpus, id2word)\n",
        "vis"
      ],
      "metadata": {
        "id": "_tKtkzdETVTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_topics = 5\n",
        "\n",
        "lda_multicore_5_topics = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
        "                                                        id2word=id2word,\n",
        "                                                        num_topics=num_topics, \n",
        "                                                        chunksize=100,\n",
        "                                                        passes=10,\n",
        "                                                        per_word_topics=True,\n",
        "                                                        workers=1, \n",
        "                                                        random_state=1234, \n",
        "                                                        iterations=10) "
      ],
      "metadata": {
        "id": "tGu_J1OgTmnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_multicore_5_topics, corpus, id2word)\n",
        "vis"
      ],
      "metadata": {
        "id": "lWCU_P8oTq68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coherence Measures\n"
      ],
      "metadata": {
        "id": "2ktNkVYUy3dC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coherence score in topic modeling measures how similar topic words are to each other. Usually, the coherence score increases with the increase in the number of topics. This increase becomes smaller as the number of topics gets higher. The best choice is a point after which the increase in coherence score is no longer worth the additional increase in the number of topics. "
      ],
      "metadata": {
        "id": "Cc-l3vI95it8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit=None, start=None, step=None):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
        "                                                        id2word=id2word,\n",
        "                                                        num_topics=num_topics, \n",
        "                                                        chunksize=100,\n",
        "                                                        passes=10,\n",
        "                                                        random_state=1234,\n",
        "                                                        per_word_topics=True,\n",
        "                                                        workers=1)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "metadata": {
        "id": "wq0w6RqiUc10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=lemmas, start=2, limit=10, step=1)"
      ],
      "metadata": {
        "id": "AQoCXRh503DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the coherence scores vs number of topics"
      ],
      "metadata": {
        "id": "vvppHfqhqxPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start=2; limit=10;  step=1;\n",
        "x = range(start, limit, step)\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.grid()\n",
        "plt.title(\"Coherence Score vs. Number of Topics\")\n",
        "plt.xticks(x)\n",
        "plt.plot(x, coherence_values, \"-o\")\n",
        "\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "UlpS4sU624qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_topics = 7\n",
        "\n",
        "lda_multicore_7_topics = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
        "                                                        id2word=id2word,\n",
        "                                                        num_topics=num_topics, \n",
        "                                                        chunksize=100,\n",
        "                                                        passes=10,\n",
        "                                                        per_word_topics=True,\n",
        "                                                        workers=1, \n",
        "                                                        random_state=1234, \n",
        "                                                        iterations=10) "
      ],
      "metadata": {
        "id": "W5QioHRy4ovv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_multicore_7_topics, corpus, id2word)\n",
        "vis"
      ],
      "metadata": {
        "id": "1TTsGpLX4w9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limitations of LDA:\n",
        "\n",
        "There are a few limitations to LDA:\n",
        "- The number of topics is fixed and must be known ahead of time.\n",
        "- LDA is unable to represent correlations that provide uncorrelated topics across the documents.\n",
        "- LDA is unsupervised.\n",
        "- LDA presumes words are exchangeable and does not account for sentence structure or multiple-word phrases.\n",
        "- LDA performs better for larger texts and is not very suitable for texts with less than 50 words.\n"
      ],
      "metadata": {
        "id": "tUDivzVa52RF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions\n",
        "\n",
        "### Frequency Analysis\n",
        "In our specific model, we worked with mock data collected by answering the question: “What are the applicants and mentees hoping to gain from the community?” Through our analysis, we found the most inherently useful graphic to be the chart of two-word token frequencies. For now, this will be the only chart we share with administrators once we create an endpoint, but new trends will likely arise with real data. The three-word tokens may then become more useful for informing admins about what the users want to gain from the community.\n",
        "\n",
        "\n",
        "### Topic Modelling\n",
        "We built the LDA model and visualized results using the pyLDAvis package. Since our coherence score peaked at num_topics = 5, we tried several different numbers of topics (3, 5, 7), but none of them showed useful topic distribution. Mostly, all the topics used the same common words but with slightly different frequencies. This result is not surprising, since there is a clear objective (topic) why the underdog-devs project was created. Moreover, LDA is not the best fit for our collection, since we worked with short texts (only 3 responses out of 335 are longer than 50 words)."
      ],
      "metadata": {
        "id": "jObIOGJYDQmw"
      }
    }
  ]
}